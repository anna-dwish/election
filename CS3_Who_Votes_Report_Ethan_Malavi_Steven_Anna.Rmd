---
title: "Case Study 3 Interim Report: Who Votes in North Carolina?"
author: "Ethan Shen, Malavi Ravindran, Steven Herrera Tenorio, Anna Darwish"
geometry: "left=1.25cm,right=1.25cm,top=1.3cm,bottom=1.3cm"
output: pdf_document
---

```{r, function checking for installed packages, include=FALSE}
# Validate that all necessary packaged have been downloaded, install otherwise or throw err package DNE
pkgTest <- function(x)
{
  if (!require(x,character.only = TRUE))
  {
    install.packages(x,repos = "http://cran.r-project.org", dep=TRUE)
    if(!require(x,character.only = TRUE)) stop("Package not found")
  }
}
```

```{r package test, include=FALSE}
# Installing packages
pkgTest("knitr")
pkgTest("tidyverse")
pkgTest("optimx")
pkgTest("lme4")
pkgTest("plyr")
pkgTest("lmerTest")
pkgTest("glmnet")
pkgTest("optimx")
pkgTest("groupdata2")
pkgTest("merTools")
pkgTest("sjPlot")
pkgTest("cvAUC")
pkgTest("pander")
pkgTest("ggplot2")
pkgTest("tidyr")
pkgTest("dplyr")
pkgTest("grid")
pkgTest("maps")
pkgTest("scales")
pkgTest("webshot")
pkgTest("magick")
pkgTest("cvms")
pkgTest("png")
```

```{r load packages, include=FALSE}
library(tidyverse)
library(optimx)
library(lme4)
library(plyr)
library(lmerTest)
library(glmnet)
library(optimx)
library(groupdata2)
library(merTools)
library(sjPlot)
library(cvAUC)
library(pander)
library(grid)
library(maps)
library(scales)
library(ggplot2)
library(tidyr)
library(dplyr)
library(webshot)
library(magick)
library(cvms)
library(png)
library(knitr)
webshot::install_phantomjs()
knitr::opts_chunk$set(echo = F)
```

# Introduction

# Exploratory Data Analysis

```{r Read Data}
who_votes_data <- readRDS("who_votes_data.Rds")
```

```{r EDA p1, fig.width=9, fig.align="center", warning=F,message=F,echo=FALSE,results='hide',fig.keep='all'}
# This code chunk prefaces some of the other package load-ins because of conflicts with select fuctionality 
who_votes_data %>% 
  dplyr::select(race_ethnicity, age_bin, gender,Likely,Unlikely) %>%
  dplyr::group_by(race_ethnicity, age_bin, gender) %>% 
  dplyr::summarize(Likely = sum(Likely), 
          Unlikely = sum(Unlikely), 
          proportion = Likely/(Likely+Unlikely)) %>% ungroup() %>% 
  ggplot(aes(x = age_bin, y = proportion, fill = gender)) + 
  geom_bar(stat = "identity", position = "dodge") + 
  facet_wrap(~race_ethnicity, nrow = 2) + 
  geom_text(aes(label=paste0(sprintf("%.2f", proportion)), y=proportion/2), 
            position = position_dodge(width = 1),  
            colour="Black", 
            size = 2.2) + 
  labs(x = expression("Age Group"), 
       y= ("Proportion of Likely Voters"), 
       title = "Likely Voters Across Age Groups, Race/Ethnicity, and Sex", 
       caption="Figure 1") +
  theme(plot.caption = element_text(hjust = 0.5, vjust = -0.5, size = 12)) +
  guides(fill=guide_legend(title="Sex"))
```

In Figure 1, we can see the proportion of likely voters across race-ethnicity, sex, and age group identities. There appears to be profound differences in likely voter proportion among the different race-ethnicity groups. *Non-Hispanic American Indian*, *Non-Hispanic Black*, and *Non-Hispanic White* groups generally have a much higher proportion of likely voters relative to other groups in North Carolina.

In general, we see an increasing trend with age for *Hispanic Any Race*, *Non-Hispanic American Indian*, *Non-Hispanic Black*, and *Non-Hispanic White* groups. This is slightly less profound for *Non-Hispanic Asian*, and *Non-Hispanic Mixed* groups.

In general, there appears to be a higher proportion of likely voters among women compared to men. For, *Hispanic Any Race*, *Non-Hispanic Asian*, and *Non-Hispanic Mixed* groups, this trend levels off for the two oldest age groups.

In general, there appears to be a higher proportion of likely voters among women compared to men. For, *Hispanic Any Race*, *Non-Hispanic Asian*, and *Non-Hispanic Mixed* groups, this trend levels off for the two oldest age groups.

```{r EDA p2, fig.width=9, fig.align="center", warning=F,message=F,echo=FALSE,results='hide',fig.keep='all'}
# http://www.peterhaschke.com/r/2013/12/05/NCmaps.html

map <- map_data("county")
nc <- subset(map, region =="north carolina")
nc$subregion <- toupper(nc$subregion)
nc <- nc %>% dplyr::rename(county_desc=subregion)

likely.by.county <- who_votes_data %>% dplyr::select(everything()) %>%
  dplyr::group_by(county_desc) %>% 
  dplyr::summarise(Likely=sum(Likely),
            Unlikely=sum(Unlikely),
            Prop=sum(Likely)/(sum(Likely) + sum(Unlikely)))
  

mapdata <- merge(nc, likely.by.county, by = "county_desc")

ggplot(data=mapdata) + 
  labs(caption="Figure 2") +
  geom_polygon(aes(x=long, y=lat, group = group, fill = Prop)) +
  scale_fill_gradient2(high="#2aa198", low="#eee8d5", "% Likely Voters By County", labels = percent) +
  theme(axis.text = element_blank(), axis.ticks = element_blank(), axis.title = element_blank(),
    panel.grid = element_blank(), legend.position=c(.2,.15), plot.caption = element_text(hjust = 0.5, vjust = -0.5, size = 12)) +
  guides(fill = guide_colorbar(title.position = "top", direction = "horizontal")) 
```

In Figure 2, we see a broad distribution of likely voter percentages. This motivates consideration of a random county intercept to account for these differences.

# Methods

To begin with our model development, we conducted exploratory data analysis to get a sense of which covariates were influential in determining likelihood to vote, along with any possible interactions. This led to our starting model: 

$$ 
\begin{aligned}
log(\frac{P_{ij}(Likely)}{1-P_{ij}(Likely)}) = \alpha_{j} + \sum_{a =1}^4\alpha_a*I(Age_{ij}=a) +\sum_{r = 5}^{9}\alpha_r*I(Race/Ethnicity_{ij}=r) + \beta_{10}(Sex_{ij}=Man) \\
\left(\begin{array}{c} 
\alpha_{a0j}\\
\alpha_{a1j}\\
\alpha_{a2j}\\
\alpha_{a3j}\\
\alpha_{a4j}
\end{array}\right)
\sim
N( \left(\begin{array}{c} 
\gamma_{0}\\
\beta_{1}\\
\beta_{2}\\
\beta_{3}\\
\beta_{4}
\end{array}\right), \left(\begin{array}{cc} 
\sigma_0^2 & \sigma_{0,a1} & \sigma_{0,2} & \sigma_{0,a3} & \sigma_{0,4}\\ 
\sigma_{1,0} & \sigma_{1}^2 & \sigma_{1,2} & \sigma_{1,3} & \sigma_{1,4}\\ 
\sigma_{2,0} & \sigma_{2,a1} & \sigma_{2}^2 & \sigma_{2,3} & \sigma_{2,4}\\ 
\sigma_{3,0} & \sigma_{3,a1} & \sigma_{3,2} & \sigma_{3}^2 & \sigma_{3,4}\\ 
\sigma_{4,0} & \sigma_{4,a1} & \sigma_{4,2} & \sigma_{4,3} & \sigma_{4}^2
\end{array}\right)) \\
A = \{ 18-29,30-39,50-64,65+ \} \\
R = \{American.Indian, Asian, Black, Mixed, White\}
\end{aligned}
$$
$$ 
\begin{aligned}
log(\frac{P_{ij}(Likely)}{1-P_{ij}(Likely)}) = \alpha_{j} + \sum_{a =1}^4\alpha_a*I(Age_{ij}=a) +\sum_{r = 5}^{9}\alpha_r*I(Race/Ethnicity_{ij}=r) + \beta_{10}(Sex_{ij}=Man) \\
\alpha_j ~
\sim
N(\alpha_0,\tau^2) \\
A = \{ 18-29,30-39,50-64,65+ \} \\
R = \{American.Indian, Asian, Black, Mixed, White\}
\end{aligned}
$$


We compared this model to one with only a random intercept for county, ones with a random intercept for county and random effect slopes for race-ethnicity and sex, and ones with interaction effects. In order to compare the fits of these models, we examined F1-scores, confusion matrices, and ROC-curves, along with binned residual plots to confirm that the underlying assumptions of each of these models were met. To compare the performance of these models, we partitioned our dataset into 6 folds and performed 5-fold cross validation, predicted on the final test set, and conducted out-of-sample prediction with the 2014 mid-term election.

We performed sensitivity analysis to validate the resulting estimates for our coefficients with a Bayesian approach, as there can be issues with convergence when developing random effect models with frequentist methods. Given the size of the dataset, we relied on relatively flat priors, and noticed that virtually all of the coefficients converged to be within two standard errors of our estimates from the frequentist approach. In addition to sensitivity analysis for our variable estimates, we also re-binned the age groups by collapsing them into the following groups: $18-39$, $40-64$, and $65+$, recreated our final model, and observed similar estimates for the other covariates. The results of this model are in Table 2 in the Appendix.

# Results and Discussion

```{r Relevel age bins}
who_votes_data$age_bin <- relevel(who_votes_data$age_bin %>% as.factor(), ref = "65+")
```

```{r cross validation, results='hide'}
set.seed(5934512) # has to be this seed
fold_df <- groupdata2::fold(who_votes_data, k = 5, cat_col = c("age_bin", "race_ethnicity", "gender","county_desc")) %>%
  mutate(vote = ifelse(prop > 0.5, 1, 0),
         vote = ifelse(is.nan(prop), 0, vote),
         vote = case_when(
           Likely == 0 & Unlikely == 0 ~ 0,
           TRUE ~ vote
         )) %>%
  mutate(vote = case_when(
    Likely == 0 & Unlikely == 0 ~ 0,
    TRUE ~ vote
))

acc_list = c()
f1_list = c()
AUC_list = c()

for (i in 1:5) {
  print(i)
  train <- fold_df %>% filter(.folds != i)
  test <- fold_df %>% filter(.folds == i)

  glmer.fit <- glmer(cbind(Likely, Unlikely) ~ age_bin * race_ethnicity + gender + (1 | county_desc),
                     data = train,
                     family = binomial,
                     control = glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun=2e5)))

  glmer.probs <- predict(glmer.fit,  test,  type = "response")
  glmer.pred <- rep(0, nrow(test))
  glmer.pred[glmer.probs > 0.5] <- 1
  
  
  acc_list[i] <-  mean(glmer.pred == test$vote)
  
  f1_list[i] <- (caret::confusionMatrix(glmer.pred %>% as.factor(), test$vote %>% as.factor()))$byClass["F1"]
  
  # AUC
  AUC_list[i] <- cvAUC::AUC(glmer.pred %>% as.double(), test$vote %>% as.double())
}

round_perc = function(x) {
  if (is.double(x)) {
    round(x*100, digits = 2)
  }
}
acc_mean = acc_list %>% mean(na.rm=T) %>% round_perc()
acc_sd = acc_list %>% sd(na.rm=T) %>% round_perc()
f1_mean = f1_list %>% mean(na.rm=T)  %>% round_perc()
f1_sd = f1_list %>% sd(na.rm=T)  %>% round_perc()
AUC_mean = AUC_list %>% mean(na.rm=T)  %>% round_perc()
AUC_sd = AUC_list %>% sd(na.rm=T)  %>% round_perc()

cv_df <- tibble(
  Accuracy = paste0(acc_mean, "% ± ", acc_sd, "%"),
  F1 = paste(f1_mean, "±", f1_sd),
  AUC = paste(AUC_mean, "±", AUC_sd)
)

glmer.fit.final <- glmer(cbind(Likely, Unlikely) ~ age_bin * race_ethnicity + gender + (1 | county_desc),
                    data = fold_df,
                    family = binomial,
                    control = glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun=2e5)))
sjPlot::tab_model(glmer.fit.final, show.re.var= TRUE,dv.labels= "Effect of Class and Course Materials", p.style = "numeric_stars", file = "results.html")
ws <- webshot("results.html", "results.png")
```
![Table 1: Random County Intercept and Age Slope Model](results.png)

```{r intercept heatmap, fig.width=9, fig.align="center", warning=F,message=F,echo=FALSE,results='hide',fig.keep='all'}

map <- map_data("county")
nc <- subset(map, region =="north carolina")
nc$subregion <- toupper(nc$subregion)
nc <- nc %>% dplyr::rename(county_desc=subregion)

county.intercepts <- as.data.frame(coef(glmer.fit.final)[1])
county.intercepts <- county.intercepts %>% dplyr::rename(intercepts=county_desc..Intercept.)
county.intercepts$count_desc <- rownames(county.intercepts)

likely.by.county$intercepts <- county.intercepts$intercepts
mapdata <- merge(nc, likely.by.county, by = "county_desc")
```

```{r intercept heatmap, fig.width=9, fig.align="center", warning=F,message=F,echo=FALSE,results='hide',fig.keep='all'}

map <- map_data("county")
nc <- subset(map, region =="north carolina")
nc$subregion <- toupper(nc$subregion)
nc <- nc %>% dplyr::rename(county_desc=subregion)

county.intercepts <- as.data.frame(coef(glmer.fit.final)[1])
county.intercepts <- county.intercepts %>% dplyr::rename(intercepts=county_desc..Intercept.)
county.intercepts$count_desc <- rownames(county.intercepts)

likely.by.county$intercepts <- county.intercepts$intercepts
mapdata <- merge(nc, likely.by.county, by = "county_desc")


ggplot(data=mapdata) + 
  labs(caption="Figure 3") +
  geom_polygon(aes(x=long, y=lat, group = group, fill = intercepts)) +
  scale_fill_gradient2(low="#ffffb7", mid="#a0d8e6", "Intercepts By County") +
  theme(axis.text = element_blank(), axis.ticks = element_blank(), axis.title = element_blank(),
    panel.grid = element_blank(), legend.position=c(.2,.15), plot.caption = element_text(hjust = 0.5, vjust = -0.5, size = 12)) +
  guides(fill = guide_colorbar(title.position = "top", direction = "horizontal")) 
```

The results of our final model can be viewed in Table ** along with a heatmap of the intercepts by county. The average accuracy and average F1-score on our test sets was `r round(test_acc,3)` and `r round(test_f1,3)` respectively. Our ROC curve also provides evidence this model fits well with an average AUC of `r round(test_AUC,3)`.

```{r initial model cm, fig.width=3,fig.height=3, fig.align="center",warning=F,message=F,echo=FALSE,results='hide',fig.keep='all'}
test.glmer.pred <- ifelse(test.glmer.pred == 0, "Unlikely", "Likely")
validation_set$vote <- ifelse(validation_set$vote == 0, "Unlikely", "Likely")
plot_confusion_matrix(confusion_matrix(test.glmer.pred,validation_set$vote))
```

From the confusion matrix, we can see that we are much more likely to commit a false negative, or incorrectly classifying a group as unlikely to vote when they are in fact likely to vote.

```{r County Random Effects Model Residual Plot,fig.height=3,fig.width=4,fig.align="center", warning=FALSE,echo=FALSE}
arm::binnedplot(x=test.glmer.probs,y=residuals(glmer.fit.final, "pearson", scaled = TRUE),
                xlab="Predicted Probabilities", 
                ylab="Binned Residuals",
                main = "Figure 4: Random County Intercept and Age Slope Model",
                cex.main=0.9, cex.lab=0.8)
# validation_set[which(test.glmer.probs > .6 &  test.glmer.probs < .7), ]
```

Our binned residuals agree with the issues we saw arise in the confusion matrix, as there is a notable majority of positive residuals, along with a few high outliers. Further examination of this issue showed that it was largely the two oldest age groups that were being misclassified, suggesting we are underestimating the effect of age on likelihood to vote. One possible explanation of this is the varying relationship of age across race-ethnicity groups. While we considered adding an interaction effect between race-ethnicity and age-group, we experienced significant convergence issues and inflated standard errors when doing so. For these reasons, we have selected this as our final model.

With respect to fixed effects, our model reflects the trend we saw with race-ethnicity and sex in our EDA. For race-ethnicity, if we hold age bin and sex constant, we are 95% confident that the odds Non-Hispanic American Indian groups are likely voters is between 1.98 and 2.11 times greater than that of Hispanic Any Race groups. With the same constraints, we are 95% confident that the odds Non-Hispanic Asian groups are likely voters is between 0.54 and 0.56 times less than that of Hispanic Any Race groups. For sex, holding age bin and race-ethnicity constant, we are 95% confident that the odds that group of men are likely voters is between 0.61 and 0.62 times less than that of women.

In regards to the random effects for county, visual comparisons between Figure 2 and Figure 3 indicate a relatively similar distribution. There appears to be slightly more homogeneity in Figure 3 in neighboring counties than Figure 2, and this is likely due to the assumption that the county intercepts stem from the same distribution.

Finally, with respect to the random effect slopes, we can examine the changing relationship of age bin and likelihood to vote. Holding race-ethnicity and sex constant, we are 95% confident the odds 18-29 year olds are likely voters is between 0.06 and 0.11 times less likely than 40-49 year olds in ** County (?). In contrast, we estimate that the odds 65+ year olds are likely voters is between 10.15 and 14.84 times more likely than 40-49 year olds in County (?).

```{r Out of sample analysis, fig.width=3, fig.width=3,fig.align="center",warning=F,message=F,echo=FALSE,results='hide',fig.keep='all'}
election2014 <- readRDS("who_votes_data_2014.Rds")
election2014 <- election2014 %>%
  mutate(vote = ifelse(prop > 0.5, 1, 0),
         vote = ifelse(is.nan(prop), 0, vote),
         vote = case_when(
           Likely == 0 & Unlikely == 0 ~ 0,
           TRUE ~ vote
         )) %>%
  mutate(vote = case_when(
    Likely == 0 & Unlikely == 0 ~ 0,
    TRUE ~ vote
))
election2014.probs <- predict(glmer.fit.final, election2014,  type = "response")
election2014.pred <- rep(0, nrow(election2014))
election2014.pred[election2014.probs > 0.5] <- 1

election2014.acc <- mean(election2014$vote == election2014.pred)
election2014.pred.cm <- ifelse(election2014.pred == 0, "Unlikely", "Likely")
election2014.vote.cm <- ifelse(election2014$vote == 0, "Unlikely", "Likely")
plot_confusion_matrix(confusion_matrix(election2014.pred.cm ,election2014.vote.cm))

```

Now, we will consider our model's ability to predict on North Carolina's 2014 Senate election. For our out of sample predictions, we achieved an `r round(election2014.acc,3)*100`% accuracy and our confusion matrix is above. These results are quite similar to our previous confusion matrix, which provides evidence that our model is capable of predicting voter trends outside of the dataset's associated election years.

# Conclusion and Limitations

Our goal in this case study were to gain a stronger understanding of the demographic composition of Noth Carolina voters relative to its overall population. By combining previous voter registration and history information with the 2020 census data, we were able to create a random effects model that accounted for the relationship between county, age, sex, and race-ethnicity and voter likelihood. By verifying our resulting model with cross validation and out of sample procedures, we were able to interpret and understand the strengths and limitations of our final model.

With respect to limitations, we will begin by noting that while ** reported biological sex, data from ** reported gender. For this reason, we could not map every gender identity from ** onto the different groups we considered. This limited us to a binary on gender. Secondly, the race-ethnicity groups from these two sources also did not align well. Another issue in this area is that we could not afford to be granular of the many different racial-ethnic groups that exist in North Carolina without significantly reducing our models' abilities to converge. Finally, the voter registration data did not include Pacific Islanders at all, so they were also excluded from our estimates.

# Appendix

## Age Bin Sensitivity

```{r age bin sensitivity df, warning=F,message=F,echo=FALSE,results='hide'}
who_votes_data_reaged <- who_votes_data
who_votes_data_reaged$age_bin <- as.character(who_votes_data_reaged$age_bin)
who_votes_data_reaged <- who_votes_data_reaged %>% mutate(age_bin = case_when(
          age_bin == "18-29" ~ "18-39",
          age_bin == "30-39" ~ "18-39",
          age_bin == "40-49" ~ "40-64",
          age_bin == "50-64" ~ "40-64",
          age_bin == "65+" ~ "65+",
          TRUE ~ age_bin))
who_votes_data_reaged <- who_votes_data_reaged %>% 
  dplyr::select(everything()) %>% 
  dplyr::group_by(county_desc,age_bin,race_ethnicity,gender) %>% 
  dplyr::summarise(Likely=sum(Likely),Unlikely=sum(Unlikely)) %>% ungroup() 
who_votes_data_reaged$age_bin <- relevel(who_votes_data_reaged$age_bin %>% as.factor(), ref = "40-64")
who_votes_data_reaged$prop = who_votes_data_reaged$Likely/(who_votes_data_reaged$Likely + who_votes_data_reaged$Unlikely)
```

```{r age bin cross validation, results='hide'}
set.seed(20) # has to be this seed
fold_df <- groupdata2::fold(who_votes_data_reaged, k = 6, cat_col = c("age_bin", "race_ethnicity", "gender","county_desc")) %>%
  mutate(vote = ifelse(prop > 0.5, 1, 0),
         vote = ifelse(is.nan(prop), 0, vote),
         vote = case_when(
           Likely == 0 & Unlikely == 0 ~ 0,
           TRUE ~ vote
         )) %>%
  mutate(vote = case_when(
    Likely == 0 & Unlikely == 0 ~ 0,
    TRUE ~ vote
))

acc_list = c()
f1_list = c()
AUC_list = c()

validation_set <- fold_df %>% filter(.folds == 6)
fold_df <- fold_df %>% filter(.folds != 6)
fold_df <- fold_df %>% filter(.folds != 5)

glmer.fit.final.reaged <- glmer(cbind(Likely, Unlikely) ~ age_bin + race_ethnicity + gender + (1 + age_bin | county_desc),
                    data = fold_df,
                    family = binomial,
                    control = glmerControl(optimizer = "optimx",
                                           calc.derivs = FALSE,
                                           optCtrl = list(method = "nlminb",
                                                          starttests=FALSE,
                                                          kkt=FALSE)))
# sjPlot::tab_model(glmer.fit.final.reaged, show.re.var= TRUE,dv.labels= "Effect of Class and Course Materials", p.style = "numeric_stars", file = "results_reaged.html")
# webshot("results_reaged.html", "results_reaged.png")
```

```{r}
# include_graphics("results_reaged.png")
```
