---
title: "Case Study 3 Interim Report: Who Votes in North Carolina?"
author: "Ethan Shen, Malavi Ravindran, Steven Herrera Tenorio, Anna Darwish"
geometry: "left=1.25cm,right=1.25cm,top=1.3cm,bottom=1.3cm"
fontsize: 12pt
output: 
  pdf_document:
     number_sections: true
---

```{r, function checking for installed packages, include=FALSE}
# Validate that all necessary packaged have been downloaded, install otherwise or throw err package DNE
pkgTest <- function(x)
{
  if (!require(x,character.only = TRUE))
  {
    install.packages(x,repos = "http://cran.r-project.org", dep=TRUE)
    if(!require(x,character.only = TRUE)) stop("Package not found")
  }
}
```

```{r package test, include=FALSE}
# Installing packages
pkgTest("knitr")
pkgTest("tidyverse")
pkgTest("optimx")
pkgTest("lme4")
pkgTest("plyr")
pkgTest("lmerTest")
pkgTest("glmnet")
pkgTest("optimx")
pkgTest("groupdata2")
pkgTest("merTools")
pkgTest("sjPlot")
pkgTest("cvAUC")
pkgTest("pander")
pkgTest("ggplot2")
pkgTest("tidyr")
pkgTest("dplyr")
pkgTest("grid")
pkgTest("maps")
pkgTest("scales")
pkgTest("webshot")
pkgTest("magick")
pkgTest("cvms")
pkgTest("png")
```

```{r load packages, include=FALSE}
library(tidyverse)
library(optimx)
library(lme4)
library(plyr)
library(lmerTest)
library(glmnet)
library(optimx)
library(groupdata2)
library(merTools)
library(sjPlot)
library(cvAUC)
library(pander)
library(grid)
library(maps)
library(scales)
library(ggplot2)
library(tidyr)
library(dplyr)
library(webshot)
library(magick)
library(cvms)
library(png)
library(knitr)
webshot::install_phantomjs()
knitr::opts_chunk$set(echo = F)
```

# Introduction

In 2019, the Supreme Court asserted that federal courts were not allowed to rule cases on partisan gerrymandering, which allows parties that control the state legislature to draw district maps and influence election outcomes (see Rucho v. Common Cause 2019). North Carolina was at the spotlight of this contested 5-4 ruling, cultivating national dialogue about the consequences of district map drawing, such as voter suppression. Our study aims to uncover demographic characteristics, such race, gender, age group, and county of residence, driving voting patterns in North Carolina. We ultimately seek to answer the following question-- *who* votes in North Carolina? Answering this will not only allow for better predictions for the outcomes of Congressional elections, but will also illuminate which demographic groups in the state are hindered from civic engagement, whether by implicit or explicit means. This information can be instrumental to campaigns and activist groups seeking to bolster support and foster more politically minded communities. 

Our study will use publicly available voter, registration, and census data in order to determine the number of likely and unlikely voters across various demographic groups in the 100 counties of North Carolina. After performing data munging and harmonization, we implement a multilevel logistic regression model with random county intercepts to make statements regarding an individual's likelihood of voting. In order to assess the performance of the model, we perform both 5-fold cross validation and out of sample validation using data from the 2012 elections. We conclude with a discussion of which demographic characteristics have a significant impact on the likelihood of voting, quantifications of these relationships, and limitations to our data and analysis 

# Data Description

Data for this study comes from North Carolina voter history, North Carolina voter registration information, and the census. Voting and registration data were used in conjunction with the census in order to not only understand who votes, but also who *does not*. Below we describe these various data sources as well as the munging and harmonization process used to obtain a singular, comprehensive dataset. 

## Voter History and Registration Data

The North Carolina voter history dataset shows how each registered voter in North Carolina, uniquely identified by a voter registration number, voted in the 2016 presidential and 2018 congressional elections. As not all voters participated in both elections, we designated those who voted in 2016 as “likely” voters for the 2020 election, and disregarded those who voted in 2018. This decision was made because both 2016 and 2020 are presidential election years, and there is generally lower turnout for midterm elections (literature review). 

The North Carolina voter registration dataset contains all legally available voter specific information for eligible voters in the state. Individuals for whom the most recent last voted date was greater than ten years were not included in the dataset. Information provided for each voter includes their county of residence, unique voter registration number, race, ethnicity, gender, and age. In this dataset, race could take on one of the following categories:

* Asian
* Black or African American
* American Indian or Alaska Native
* Two or more races 
* Other
* Native Hawaiian or Pacific Islander
* Undesignated
* White

Ethnicity was one of the following:

* Hispanic or Latino
* Not Hispanic or Not Latino
* Undesignated

And gender belonged to one of: 
* Male
* Female
* Undetermined

Recall that, in our study, a "likely" voter was one who voted in the 2016 election. Thus, not all individuals in the North Carolina registration dataset were necessarily “likely” voters. This is because certain individuals who were registered to vote and *did* vote within the last 10 years still may not have voted in the 2016 election. Thus, upon joining the voter and registration data by unique voter registration number, only those individuals who were both registered and voted in the 2016 election were preserved. In this sense, only “likely” voters remained in the merged data frame. 

Next, certain modifications were made to facilitate analysis. Firstly, age was converted to a categorical variable, $age \ bin$, which belonged to one of five categories. 

* 18-29
* 30-39
* 40-49
* 50-64
* 65+ 

In addition, the individual race and ethnic identities were combined into a $race \ and \ ethnicity$ variable which was one of:

* Hispanic any race
* Non Hispanic White
* Non Hispanic Black
* Non Hispanic Other
* Non Hispanic Asian
* Non Hispanic Mixed
* Non Hispanic American Indian or Alaska Native
* Non Hispanic Native Hawaiian or Pacific Islander
* Undetermined

Note that all individuals of hispanic ethnicity were grouped into one category, regardless of racial identity. Once these modifications were made, the data was grouped by $county$, $race \ and \ ethnicity$, $age \ bin$, and $gender$. The size of each group, which is synonymous with the number of likely voters in that group, was included in the data frame as well. For example, one row of the grouped data frame would report the number of likely voters among 18-29 year old, hispanic women in Alamance county. This dataset will be referred to as “Voting and Registration” for the continuation of the paper.

## Census Data

The data harmonization process described above finds the number of likely voters, by demographic, in the 2020 election. However, this process does not account for the population of North Carolinans who are not likely to vote. Thus, in order to properly address the question of who does and does not vote in North Carolina, census data was utilized. This data helped to provide a better sense of the denominator in our calculations-- that is, what is the *total* size of each demographic group in each of the 100 counties in North Carolina? 

The census data includes, for each county, census year, and age group, the population size by various demographic identities. Examples of these groups include females, hispanic males, and non hispanic females who identify as black alone or in combination. It is clear that the groups represented in the census data range from very broad (gender) to very granular (a combination of gender, ethnicity, and race). As these granular identities account for both race and ethnicity, they were consistent with the $race \ and \ ethnicity$ variable defined in the “Voting and Registration” dataset. In contrast, age bins in the census were of size 5, which was smaller than those defined in "Voting and Registration."

To join "Voting and Registration" with the census data, the census data was filtered for the most recent year (2020) and for age groups that were at or greater than the 15-19 bin. For those rows where the age group of interest fell within the 15-19 bin, each population size was divided by 2.5 in order to theoretically account for only those individuals who were 18 or above (and thus eligible to vote). Then, population information was summed over the smaller age groupings to create age bins consistent with those of "Voting and Registration." For example, population counts from bins 4, 5, and 6 (which mapped to 18-19, 20-24, and 25-29, respectively) were summed together in order to represent counts for the 18-29 bin. Finally, using the census counts provided for each demographic group (by gender, age group, and race and ethnicity) within each county, a new dataframe was constructed with each row representing a county, racial and ethnic group, age bin, and gender and total group size. As can be seen, the format of this dataset was consistent with “Voting and Registration,” but with a column representing the $total$ group size rather than the size of likely voters. This dataset will be referred to as “Census”.

The “Voting and Registration” and “Census” datasets were then merged by county, age bin, race and ethnicity, and gender. This final data frame reports, for each demographic group within each county, the number of likely voters (our numerator of interest) as well as the total size (our denominator of interest). This merging process was not perfect, as there were some inconsistencies between information provided by the "Census" and "Voting and Registration" datasets. For example, the census provided counts of only male and female populations. For this reason, those registered voters who specified a gender other than male or female were omitted in this dataset. Those with undesignated racial and ethnic identities were excluded for similar reasons. Similarly, we found that there were no instances of "Native Hawaiian or Pacific Islander" individuals who voted in 2016, necessating their removal from the dataset. The limitations of these decisions will be discussed more thoroughly in section ____. 


# Exploratory Data Analysis

```{r Read Data}
who_votes_data <- readRDS("who_votes_data_2016.Rds")
```

```{r EDA p1, fig.width=9, fig.align="center", warning=F,message=F,echo=FALSE,results='hide',fig.keep='all'}
# This code chunk prefaces some of the other package load-ins because of conflicts with select fuctionality 
who_votes_data %>% 
  dplyr::select(race_ethnicity, age_bin, gender,Likely,Unlikely) %>%
  dplyr::group_by(race_ethnicity, age_bin, gender) %>% 
  dplyr::summarize(Likely = sum(Likely), 
                   Unlikely = sum(Unlikely), 
                   proportion = Likely/(Likely+Unlikely)) %>% ungroup() %>% 
  ggplot(aes(x = age_bin, y = proportion, fill = gender)) + 
  geom_bar(stat = "identity", position = "dodge") + 
  facet_wrap(~race_ethnicity, nrow = 2) + 
  geom_text(aes(label=paste0(sprintf("%.2f", proportion)), y=proportion/2), 
            position = position_dodge(width = 1),  
            colour="Black", 
            size = 2.2) + 
  labs(x = expression("Age Group"), 
       y= ("Proportion of Likely Voters"), 
       title = "Likely Voters Across Age Groups, Race/Ethnicity, and Sex", 
       caption="Figure 1") +
  theme(plot.caption = element_text(hjust = 0.5, vjust = -0.5, size = 12)) +
  guides(fill=guide_legend(title="Sex"))
```

In Figure 1, we can see the proportion of likely voters across race-ethnicity, sex, and age group identities. There appears to be profound differences in likely voter proportion among the different race-ethnicity groups. *Hispanic Any Race*, *Non-Hispanic American Indian*, *Non-Hispanic Black*, and *Non-Hispanic White* groups generally have a much higher proportion of likely voters relative to other groups in North Carolina.

In general, we see an increasing trend in the proportion of likely voters with age for *Non-Hispanic American Indian*, *Non-Hispanic Black*, and *Non-Hispanic White* groups. This trend is actually reversed for *Non-Hispanic Mixed* groups. For *Hispanic Any Race* and *Non-Hispanic Asian* groups, we see a varying relationship that is slightly less profound. These trends point to a potential interaction effect between age and $race \ and \ ethnicity$. 

In general, there appears to be a higher proportion of likely voters among women compared to men. However, we see this trend level off in the two oldest age groups.

```{r EDA p2, fig.width=9, fig.align="center", warning=F,message=F,echo=FALSE,results='hide',fig.keep='all'}
# http://www.peterhaschke.com/r/2013/12/05/NCmaps.html

map <- map_data("county")
nc <- subset(map, region =="north carolina")
nc$subregion <- toupper(nc$subregion)
nc <- nc %>% dplyr::rename(county_desc=subregion)

likely.by.county <- who_votes_data %>% dplyr::select(everything()) %>%
  dplyr::group_by(county_desc) %>% 
  dplyr::summarise(Likely=sum(Likely),
                   Unlikely=sum(Unlikely),
                   Prop=sum(Likely)/(sum(Likely) + sum(Unlikely)))


mapdata <- merge(nc, likely.by.county, by = "county_desc")

ggplot(data=mapdata) + 
  labs(caption="Figure 2") +
  geom_polygon(aes(x=long, y=lat, group = group, fill = Prop)) +
  scale_fill_gradient2(high="#301934", low="#b19cd9", "% Likely Voters By County") +
  theme(axis.text = element_blank(), axis.ticks = element_blank(), axis.title = element_blank(),
        panel.grid = element_blank(), legend.position=c(.2,.15), plot.caption = element_text(hjust = 0.5, vjust = -0.5, size = 12), legend.key.width = unit(3,"line")) +
  guides(fill = guide_colorbar(title.position = "top", direction = "horizontal")) 
```

In Figure 2, we see how the proportion of likely voters varies throughout North Carolina. Heterogeneity among the various counties motivates a consideration of random county intercepts in modelling the likelihood of voting. Some interesting trends can be seen in the state map. Cherokee county, which is the westernmost county in the state, has an extremely high proportion of likely voters. This county is 95% White and heavily Republican, with 75% of the vote going to Donald Trump in 2016. Watauga County, located slightly northeast of Cherokee, similarly shows a high proportion of likely voters. However, despite being similar in racial composition to Cherokee (96% White), growth of a younger voting population, brought forth by Appalachian State University, has turned Watauga into a hotly contested swing county.  

# Methods

To begin with our model development, we conducted exploratory data analysis to get a sense of which covariates were influential in determining likelihood to vote, along with any possible interactions. This led to our starting model: 

$$ 
\begin{aligned}
log(\frac{P_{ij}(Likely)}{1-P_{ij}(Likely)}) = \alpha_{j} + \alpha_{1} * I(Gender_{ij}=Male &) + \sum_{a = 2}^5\alpha_{2a}*I(Age_{ij}=a) + \  \\
\sum_{r = 2}^{6}\alpha_{3r}*I(Race/Ethnicity_{ij}=r) +\sum_{c = 11}^{30}\alpha_{4c}*I (&Age_{ij}, \ Race/Ethnicity_{ij}=c)& (1)  \\
\alpha_j \sim N(\alpha_0,\tau^2)
\end{aligned}
$$

$P_{ij}$ is the probability that individual $i$ from county $j$ will vote in the upcoming election, and $alpha_j$ represents the random intercept term for each county. For the *Age* term, we encode $a=1$ as our baseline, $65+$ year olds and then code the remaining in increasing age-bin order. For our *Race/Ethnicitiy* term, we encode $r=1$, *Hispanic Any Race*, as our baseline group. The remaining *Race/Ethnicity* identities are ordered as follows: *\{Non-Hispanic American Indian, Non-Hispanic Asian, Non-Hispanic Black, Non-Hispanic Mixed, Non-Hispanic White\}*. Finally, as there are five age bins and six race/ethnicity groups, meaning thirty possible combinations, 10 of these involve the baseline terms, leaving 20 other combinations to appear as evaluated terms in our model.

We compared this model to one without an interaction between *Age* and *Race/Ethnicity*, ones with a random intercept for county and random effect slopes for the three demographic covariates, and other interaction effects. In order to compare the fits of these models, we examined accuracy, $F_1$-scores, confusion matrices, and ROC curves, along with binned residual plots to confirm that the underlying assumptions of each of these models were met. To compare the performance of these models, we performed 5-fold cross validation and conducted out-of-sample prediction with the 2012 presidential election.

We performed sensitivity analysis to validate the resulting estimates for our coefficients with a Bayesian approach, as there can be issues with convergence when developing random effect models with frequentist methods. Given the size of the dataset, we relied on relatively flat priors, and noticed that virtually all of the coefficients converged to be within two standard errors of our estimates from the frequentist approach. In addition to sensitivity analysis for our variable estimates, we also re-binned the age groups by collapsing them into the following groups: $18-39$, $40-64$, and $65+$, recreated our final model, and observed similar estimates for the other covariates. The results of this model are in Table 2 in the Appendix.

# Results and Discussion

```{r Relevel age bins}
who_votes_data$age_bin <- relevel(who_votes_data$age_bin %>% as.factor(), ref = "65+")
```

```{r cross validation, warning=FALSE, message=F}

set.seed(5934512) # has to be this seed
fold_df <- groupdata2::fold(who_votes_data, k = 5, cat_col = c("age_bin", "race_ethnicity", "gender","county_desc")) %>%
  dplyr::mutate(vote = ifelse(prop > 0.5, 1, 0),
                vote = ifelse(is.nan(prop), 0, vote),
                vote = dplyr::case_when(
                  Likely == 0 & Unlikely == 0 ~ 0,
                  TRUE ~ vote
                )) 

acc_list = c()
f1_list = c()
AUC_list = c()

for (i in 1:5) {
  train <- fold_df %>% filter(.folds != i)
  test <- fold_df %>% filter(.folds == i)
  
  glmer.fit <- glmer(cbind(Likely, Unlikely) ~ age_bin + race_ethnicity + gender + age_bin * race_ethnicity + (1 | county_desc),
                     data = train,
                     family = binomial,
                     control = glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun=2e5)))
  
  glmer.probs <- predict(glmer.fit,  test,  type = "response")
  glmer.pred <- rep(0, nrow(test))
  glmer.pred[glmer.probs > 0.5] <- 1
  
  
  acc_list[i] <-  mean(glmer.pred == test$vote)
  
  f1_list[i] <- (caret::confusionMatrix(glmer.pred %>% as.factor(), test$vote %>% as.factor()))$byClass["F1"]
  
  # AUC
  AUC_list[i] <- cvAUC::AUC(glmer.pred %>% as.double(), test$vote %>% as.double())
}

round_perc = function(x) {
  if (is.double(x)) {
    round(x*100, digits = 2)
  }
}
acc_mean = acc_list %>% mean(na.rm=T) %>% round_perc()
acc_sd = acc_list %>% sd(na.rm=T) %>% round_perc()
f1_mean = f1_list %>% mean(na.rm=T)  %>% round_perc()
f1_sd = f1_list %>% sd(na.rm=T)  %>% round_perc()
AUC_mean = AUC_list %>% mean(na.rm=T)  %>% round_perc()
AUC_sd = AUC_list %>% sd(na.rm=T)  %>% round_perc()

cv_df <- tibble(
  Accuracy = paste0(acc_mean, "% ± ", acc_sd, "%"),
  F1 = paste(f1_mean, "±", f1_sd),
  AUC = paste(AUC_mean, "±", AUC_sd)
)

glmer.fit.final <- glmer(cbind(Likely, Unlikely) ~ age_bin + race_ethnicity + gender + age_bin * race_ethnicity + (1 | county_desc),
                         data = fold_df,
                         family = binomial,
                         control = glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun=2e5)))

results <- data.frame(VarCorr(glmer.fit.final))
final.model.random.results <- data.frame("Intercept"=c(round(results[1,4],3)),"Std.Dev"=c(round(results[1,5],3)))

final.model.fixed.results = data.frame(Estimates=summary(glmer.fit.final)$coefficients[, 1], 
                                       Std.Err=summary(glmer.fit.final)$coefficients[, 2], 
                                       P.Value=summary(glmer.fit.final)$coefficients[, 4])
```


```{r intercept heatmap, fig.width=9, fig.align="center", warning=F,message=F,echo=FALSE,results='hide',fig.keep='all'}

map <- map_data("county")
nc <- subset(map, region =="north carolina")
nc$subregion <- toupper(nc$subregion)
nc <- nc %>% dplyr::rename(county_desc=subregion)

county.intercepts <- as.data.frame(coef(glmer.fit.final)[1])
county.intercepts <- county.intercepts %>% dplyr::rename(intercepts=county_desc..Intercept.)
county.intercepts$count_desc <- rownames(county.intercepts)

likely.by.county$intercepts <- county.intercepts$intercepts
mapdata <- merge(nc, likely.by.county, by = "county_desc")


ggplot(data=mapdata) + 
  labs(caption="Figure 3") +
  geom_polygon(aes(x=long, y=lat, group = group, fill = intercepts)) +
  scale_fill_gradient2(low="#948294", mid="#543c54", high="#281934", "Intercepts By County") +
  theme(axis.text = element_blank(), axis.ticks = element_blank(), axis.title = element_blank(),
        panel.grid = element_blank(), legend.position=c(.2,.15), plot.caption = element_text(hjust = 0.5, vjust = -0.5, size = 12),
        legend.key.width =unit(3,"line")) +
  guides(fill = guide_colorbar(title.position = "top", direction = "horizontal")) 
```

The results of our final model can be viewed in Table 1 in our Appendix, and Figure 3 is a heatmap of the intercepts by county. While the intercepts appear to generally capture relative trends, these intercepts appear to be more homogeneous than the true percent of likely voters. This is likely a consequence of our assumption that they stem from the same distribution. The average accuracy and average F1-score on our test sets were `r cv_df$Accuracy` and `r cv_df$F1` respectively. Our ROC curve also provides evidence this model fits well with an average AUC of `r cv_df$AUC`.

```{r initial model cm, fig.width=3,fig.height=3, fig.align="center",warning=F,message=F,echo=FALSE,results='hide',fig.keep='all'}
test.glmer.probs <- predict(glmer.fit.final,fold_df,type="response")
test.glmer.preds <- ifelse(test.glmer.probs <= 0.5, "Unlikely", "Likely")
test.actual.cm <- ifelse(fold_df$vote == 0, "Unlikely", "Likely")
plot_confusion_matrix(confusion_matrix(test.glmer.preds,test.actual.cm))
```

From the confusion matrix, we can see a relatively even split of false negatives and false positives, suggesting our model isn't predisposed to making either mistake more than the other. 

```{r County Random Effects Model Residual Plot,fig.height=3,fig.width=4,fig.align="center", warning=FALSE,echo=FALSE}
arm::binnedplot(x=test.glmer.probs,y=residuals(glmer.fit.final, "pearson", scaled = TRUE),
                xlab="Predicted Probabilities", 
                ylab="Binned Residuals",
                main = "Figure 4: Random County Intercept and Age Slope Model",
                cex.main=0.9, cex.lab=0.8)
# validation_set[which(test.glmer.probs > .6 &  test.glmer.probs < .7), ]
```

Our binned residuals, however, reveal some issues for our model. We appear to be consistently underestimating the likelihood of voting for groups that are less likely to vote, along with a fanning of a residuals as the likelihood increases. This may cause issues as groups that are less likely to vote have been more active in the past few elections [CITE] and is important to keep in mind. Another possible cause of this issue was the non-linear relationships between age bins and some Race/Ethnicity groups in our exploratory data analysis. This curvature is more clearly visualized in Figure 4, which is a binned residual plot resulting from the same model but without the interaction effect between Race/Ethnicity and age. Another issue to consider are the slight differences in the heatmaps, which suggested some differences in counties with very high and very low voter turnout. While we considered several transformations to better capture the nuances of this relationship, we experienced convergence issues and inflated standard errors.

With respect to fixed effects, ...

In regards to the random effects for county, ...

```{r Out of sample analysis, fig.width=3, fig.width=3,fig.align="center",warning=F,message=F,echo=FALSE,results='hide',fig.keep='all'}
election2012 <- readRDS("who_votes_data_2012.Rds")
election2012 <- election2012 %>%
  mutate(vote = ifelse(prop > 0.5, 1, 0),
         vote = ifelse(is.nan(prop), 0, vote),
         vote = case_when(
           Likely == 0 & Unlikely == 0 ~ 0,
           TRUE ~ vote
         )) %>%
  mutate(vote = case_when(
    Likely == 0 & Unlikely == 0 ~ 0,
    TRUE ~ vote
  ))
election2012.probs <- predict(glmer.fit.final, election2012,  type = "response")
election2012.pred <- rep(0, nrow(election2012))
election2012.pred[election2012.probs > 0.5] <- 1

election2012.acc <- mean(election2012$vote == election2012.pred)
election2012.pred.cm <- ifelse(election2012.pred == 0, "Unlikely", "Likely")
election2012.vote.cm <- ifelse(election2012$vote == 0, "Unlikely", "Likely")
plot_confusion_matrix(confusion_matrix(election2012.pred.cm ,election2012.vote.cm))

```

Now, we will consider our model's ability to predict on voting likelihood for the 2012 presidential election. For our out of sample predictions, we achieved an `r round(election2012.acc,3)*100`% accuracy and our confusion matrix is above. These results are quite similar to our previous confusion matrix, which provides evidence that our model is capable of predicting voter trends outside of the dataset's associated election years.

# Conclusion and Limitations

Our goal in this case study were to gain a stronger understanding of the demographic composition of Noth Carolina voters relative to its overall population. By combining previous voter registration and history information with the 2020 census data, we were able to create a random effects model that accounted for the relationship between county, age, sex, and race-ethnicity and voter likelihood. By verifying our resulting model with cross validation and out of sample procedures, we were able to interpret and understand the strengths and limitations of our final model.

With respect to limitations, we will begin by noting that the census solely designates individuals as "Male" and "Female," severly limiting the scope of gender identity. For this reason, we had to exclude those individuals who did not report themselves as "Male" or "Female" from our analysis. Secondly, the racial and ethnic groups from these two sources also did not align perfectly. For example, individuals from the registration dataset could only report belonging to one racial and ethnic group. Conversely, individuals on the census could check multiple racial categories. Thus, mapping these identities between the two data sources was not perfect. Similarly, the voter registration data did not include any instances of Pacific Islanders and Native Hawaiians, so these individuals were removed from our analysis. 

# Appendix

## Model Results

```{r}
pander(final.model.fixed.results, caption = "Random County Intercept Model")
```


## No Interaction Effect

```{r cross validation no intrxn, results='hide',message=F}
set.seed(5934512) # has to be this seed
fold_df <- groupdata2::fold(who_votes_data, k = 5, cat_col = c("age_bin", "race_ethnicity", "gender","county_desc")) %>%
  mutate(vote = ifelse(prop > 0.5, 1, 0),
         vote = ifelse(is.nan(prop), 0, vote),
         vote = case_when(
           Likely == 0 & Unlikely == 0 ~ 0,
           TRUE ~ vote
         )) %>%
  mutate(vote = case_when(
    Likely == 0 & Unlikely == 0 ~ 0,
    TRUE ~ vote
  ))

glmer.fit.final <- glmer(cbind(Likely, Unlikely) ~ age_bin + race_ethnicity + gender + (1 | county_desc),
                         data = fold_df,
                         family = binomial,
                         control = glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun=2e5)))
```

```{r initial model cm no intrxn, fig.width=3,fig.height=3, fig.align="center",warning=F,message=F,echo=FALSE,results='hide',fig.keep='all'}
test.glmer.probs <- predict(glmer.fit.final,fold_df,type="response")
test.glmer.preds <- ifelse(test.glmer.probs <= 0.5, "Unlikely", "Likely")
test.actual.cm <- ifelse(fold_df$vote == 0, "Unlikely", "Likely")
plot_confusion_matrix(confusion_matrix(test.glmer.preds,test.actual.cm))
```

```{r County Random Effects Model Residual Plot no intrxn,fig.height=3,fig.width=4,fig.align="center", warning=FALSE,echo=FALSE}
arm::binnedplot(x=test.glmer.probs,y=residuals(glmer.fit.final, "pearson", scaled = TRUE),
                xlab="Predicted Probabilities", 
                ylab="Binned Residuals",
                main = "Figure 4: Random County Intercept and Age Slope Model",
                cex.main=0.9, cex.lab=0.8)
```

```{r Out of sample analysis no intrxn, fig.width=3, fig.width=3,fig.align="center",warning=F,message=F,echo=FALSE,results='hide',fig.keep='all'}
election2012 <- readRDS("who_votes_data_2012.Rds")
election2012 <- election2012 %>%
  mutate(vote = ifelse(prop > 0.5, 1, 0),
         vote = ifelse(is.nan(prop), 0, vote),
         vote = case_when(
           Likely == 0 & Unlikely == 0 ~ 0,
           TRUE ~ vote
         )) %>%
  mutate(vote = case_when(
    Likely == 0 & Unlikely == 0 ~ 0,
    TRUE ~ vote
  ))
election2012.probs <- predict(glmer.fit.final, election2012,  type = "response")
election2012.pred <- rep(0, nrow(election2012))
election2012.pred[election2012.probs > 0.5] <- 1

election2012.acc <- mean(election2012$vote == election2012.pred)
election2012.pred.cm <- ifelse(election2012.pred == 0, "Unlikely", "Likely")
election2012.vote.cm <- ifelse(election2012$vote == 0, "Unlikely", "Likely")
plot_confusion_matrix(confusion_matrix(election2012.pred.cm ,election2012.vote.cm))

```

## Age Bin Sensitivity

```{r age bin sensitivity df, warning=F,message=F,echo=FALSE,results='hide'}
who_votes_data_reaged <- who_votes_data
who_votes_data_reaged$age_bin <- as.character(who_votes_data_reaged$age_bin)
who_votes_data_reaged <- who_votes_data_reaged %>% mutate(age_bin = case_when(
  age_bin == "18-29" ~ "18-39",
  age_bin == "30-39" ~ "18-39",
  age_bin == "40-49" ~ "40-64",
  age_bin == "50-64" ~ "40-64",
  age_bin == "65+" ~ "65+",
  TRUE ~ age_bin))
who_votes_data_reaged <- who_votes_data_reaged %>% 
  dplyr::select(everything()) %>% 
  dplyr::group_by(county_desc,age_bin,race_ethnicity,gender) %>% 
  dplyr::summarise(Likely=sum(Likely),Unlikely=sum(Unlikely)) %>% ungroup() 
who_votes_data_reaged$age_bin <- relevel(who_votes_data_reaged$age_bin %>% as.factor(), ref = "65+")
who_votes_data_reaged$prop = who_votes_data_reaged$Likely/(who_votes_data_reaged$Likely + who_votes_data_reaged$Unlikely)
```

```{r age bin sensitivity analysis model results, results="hide"}
fold_df <- groupdata2::fold(who_votes_data_reaged, k = 5, cat_col = c("age_bin", "race_ethnicity", "gender","county_desc")) %>%
  dplyr::mutate(vote = ifelse(prop > 0.5, 1, 0),
                  vote = ifelse(is.nan(prop), 0, vote),
                  vote = dplyr::case_when(
                      Likely == 0 & Unlikely == 0 ~ 0,
                      TRUE ~ vote
                  )) 

acc_list = c()
f1_list = c()
AUC_list = c()

glmer.fit.final.reaged <- glmer(cbind(Likely, Unlikely) ~ age_bin * race_ethnicity + gender + (1 | county_desc),
                                data = fold_df,
                                family = binomial,
                                control = glmerControl(optimizer = "optimx",
                                                       calc.derivs = FALSE,
                                                       optCtrl = list(method = "nlminb",
                                                                      starttests=FALSE,
                                                                      kkt=FALSE)))
results.reaged <- data.frame(VarCorr(glmer.fit.final.reaged))
final.model.random.results.reaged <- data.frame("Intercept"=c(round(results.reaged[1,4],3)),"Std.Dev"=c(round(results.reaged[1,5],3)))

final.model.fixed.results.reaged = data.frame(Estimates=summary(glmer.fit.final.reaged)$coefficients[, 1], 
                                              Std.Err=summary(glmer.fit.final.reaged)$coefficients[, 2], 
                                              P.Value=summary(glmer.fit.final.reaged)$coefficients[, 4])
```

```{r}
pander(final.model.fixed.results.reaged, caption = "Age Bin Sensitivity Analysis Model")
```

